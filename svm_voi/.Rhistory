library(dplyr)
library(lme4)
library(e1071)
library(lmtest)
library(lubridate)
library(knitr)
library(BaylorEdPsych)
data_path <- '/Users/kelly/cueexp/data/relapse_data/relapse_data_180330.csv'
setwd('/Users/kelly/cueexp/scripts/nick_relapse_scripts')
df <- read.csv(data_path)
df$relapse <- as.factor(df$relapse)
df$relIn6Months <- as.factor(df$relIn6Mos)
df$Subject <- df$subj
df <- filter(df, Subject !='tf151127', Subject!= 'er171009')
filterMotion <- function(mask, tr, condition){
var <- paste0(mask,'_', condition, '_TR', tr)
print(var)
col <- df[var]
print(sum(col>4))
df[var][col>4] <- NA
print(sum(is.na(df[var])))
}
print(colnames(df))
for (mask in c('nacc','acc', 'ains', 'mpfc', 'vta')){
for (tr in c("3", "4", "5", "6", '7', '567mean')){
for( condition in c('drugs', 'food', 'neutral')){
filterMotion(mask, tr, condition)
}
}
}
hist(df$nacc_drugs_TR567mean)
df$Subject <- df$subjid
evalClassifier <- function(df, formula, type='glm', split.method='8020', sep.subjects=FALSE, print.model=FALSE){
# first get rid of any rows in which one of our variables is NA)
formula.vars <- unlist(strsplit(gsub("[^[:alnum:]|'_' ]", "", as.character(formula)), c(' ')))
for(v in formula.vars){
if(v %in% colnames(df)) {
df <- df[!is.na(df[v]), ]
}
}
# make our results data frame.
d.res <<- data.frame()
if(sep.subjects){
print("No separate subject implementation here.")
} else {
if(split.method=='loso'){
#eval_model on each subjects
if(type=='glm'){
print("Evaluating Entire Model")
# first evaluate the entire model so as to print model summary information
.evalClassifier(df, formula, type, split.method = 'none', print.model = print.model)
}
print("Beginning LOSO...")
for(subj in unique(df$Subject)){
print(nrow((filter(df, Subject==subj))))
accuracies <<- .evalClassifier(df, formula, type, split.method, test.sub=subj, print.model = print.model)
d.res<<- rbind(d.res, data.frame(Subject=subj, accuracies))
break
}
d.res <- d.res[order(-d.res$test.accuracy),] # order the subjects by their classifier accuracy
# add the average of all the subjects
d.res<- rbind(d.res, data.frame(Subject='Average', t(colMeans(d.res[,-1]))))
} else{
accuracies <- .evalClassifier(df, formula, type, split.method, print.model=TRUE)
d.res <- rbind(d.res, data.frame(data='All', accuracies))
}
}
d.res
}
.evalClassifier <- function(df, formula, type='glm', split.method='loso', test.sub = '',  print.model=FALSE){
y <- all.vars(formula)[1] # get the y variable name to do train test splits
if(split.method=='none' && type=='glm'){
m <- fitModel(df, df, formula, type, print.model=TRUE)
} else {
train.test <<- trainTestSplit(df, split.method, y=y,test.sub=test.sub)
m <- fitModel(df, train.test$train, formula, type, print.model)
train.accuracy <- modelAccuracy(m, y, train.test$train, type)
if(split.method=='loso'){
test.accuracy  <- modelAccuracy(m, y, train.test$test, type, one_prediction=T)
return( list('train.accuracy'=train.accuracy, 'test.accuracy'=test.accuracy[1], 'prediction'=test.accuracy[2], 'ground.truth' = test.accuracy[3]))
} else{
test.accuracy  <- modelAccuracy(m, y, train.test$test, type)
}
list('train.accuracy'=train.accuracy, 'test.accuracy'=test.accuracy[1])
}
}
trainTestSplit <- function(df, split.method='8020', y='result', test.sub="", downsample=TRUE){
set.seed(0)
# Assume that the two responses are levels 1, 2 of a factor
ind1 <- which(as.numeric(df[,y])==2)
ind0 <- which(as.numeric(df[,y])==1)
# downsample results. to upsample, use max and replace = TRUE
# uncomment section below for one_subj
if(downsample){
sampsize <- min(length(ind1), length(ind0))
sampind1 <- sample(ind1, sampsize, replace = FALSE)
sampind0 <- sample(ind0, sampsize, replace = FALSE)
sampind <- sample(c(sampind1,sampind0)) # the outside call to sample should randomize
} else{
sampind <- sample(1:nrow(df))
}
balanced.df <- df[sampind,]
#Change response levels to 0,1 from 1, 2
balanced.df[,y] <- factor(as.numeric(balanced.df[,y])-1, levels=c(0,1))
#return last day
if(split.method=='8020'){
nrows <- nrow(balanced.df)
train.ind <- sample(1:nrows, size=floor(.8 * nrows))
test.ind <- c(1:nrows)[!c(1:nrows) %in% train.ind]
d.train = balanced.df[train.ind,]
d.test  =balanced.df[test.ind,]
l <- list("train" = d.train, "test" = d.test)
} else if(split.method=='loso'){
train.ind <- balanced.df$Subject!= test.sub
test.ind <- balanced.df$Subject==test.sub
d.train <<- balanced.df[train.ind,]
d.test  <<- balanced.df[test.ind,]
l <- list("train" = d.train, "test" = d.test)
} else {
print('trainTestSplit called with split.method != 8020 or loso')
}
l
}
modelAccuracy <- function(m, y, d.test, type='glm', one_prediction=FALSE){
if(type=='glm'){
pred = predict(m, newdata = d.test, type = 'response', allow.new.levels = TRUE)
pred.bin = factor(ifelse(pred >= 0.5,1,0), levels = c(0,1))
}
if(type=='svm'){
pred = predict(m, d.test)
pred.bin <- factor(as.numeric(pred), levels=c(1,2), labels=c(0,1))
}
if(type=='naivebayes'){
pred = predict(m, d.test, type='raw')[,2]
pred.bin = factor(ifelse(pred >= 0.5,1,0), levels = c(0,1))
}
if(one_prediction){
prediction <- as.integer(pred.bin[1]) - 1
}
class.tab = table(real=d.test[,y], model=pred.bin)
#print(class.tab)
acc <- (class.tab[1,1])/sum(class.tab)
try(acc <- acc +  class.tab[2,2]/sum(class.tab))
if(one_prediction){
return(c(acc, prediction, as.integer(d.test[,y][1])-1))
}
acc
}
fitModel <- function(df, d.train, formula, type='glm', print.model=TRUE){
# glimpse(d.train)
needs.multilevel <- '|' %in% unlist(strsplit(gsub("[^[:alnum:]|'_' ]", "", as.character(formula)), c(' ')))
if(type=='glm'){
if(needs.multilevel){
null_formula <- as.formula(paste(as.character(formula)[2], '~', '(1 | Subject)'))
model <- glmer(formula, data = df, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
m2 <- glmer(null_formula, data = df, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
if(print.model){
print(summary(model), correlation=T)
if(needs.multilevel){
print(rsquared.glmm(model))
}
print(lrtest(m2, model))
print(anova(model))
#print(confint(model))
}
model <- glmer(formula, data = d.train, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
} else{
null_formula <- as.formula(paste(as.character(formula)[2], '~', '1'))
model <- glm(formula, data=df, family="binomial")
m2 <- glm(null_formula, data=df, family="binomial")
if(print.model){
print(summary(model))
print(PseudoR2(model))
print(lrtest(m2, model))
print(anova(model))
}
#print(summary(d.train))
model <- glm(formula, data=d.train, family="binomial")
}
}
if(type=='svm'){
model <- svm(formula, data=d.train)
}
if(type=='naivebayes'){
if(needs.multilevel){
print('naiveBayes cannot handle interaction terms')
} else{
model <-  naiveBayes(formula, data=d.train)
}
}
model
}
formula <- as.formula("relIn6Mos~ nacc_drugs_beta + years_of_use + bam_upset ")
res <- evalClassifier(df, formula, type='glm', split.method='loso')
head(df)
df$relIn6Months
df$relIn6Mos
length(df$relIn6Mos)
length(df$relIn6Months)
library(dplyr)
library(lme4)
library(e1071)
library(lmtest)
library(lubridate)
library(knitr)
library(BaylorEdPsych)
data_path <- '/Users/kelly/cueexp/data/relapse_data/relapse_data_180330.csv'
setwd('/Users/kelly/cueexp/scripts/nick_relapse_scripts')
df <- read.csv(data_path)
#remove subjects without relapse data
df = df[is.na(df$relapse) == FALSE,]
#df <- filter(df, Subject !='tf151127', Subject!= 'er171009')
df$relapse <- as.factor(df$relapse)
df$relIn6Mos <- as.factor(df$relIn6Mos)
df$Subject <- df$subj
filterMotion <- function(mask, tr, condition){
var <- paste0(mask,'_', condition, '_TR', tr)
print(var)
col <- df[var]
print(sum(col>4))
df[var][col>4] <- NA
print(sum(is.na(df[var])))
}
print(colnames(df))
for (mask in c('nacc','acc', 'ains', 'mpfc', 'vta')){
for (tr in c("3", "4", "5", "6", '7', '567mean')){
for( condition in c('drugs', 'food', 'neutral')){
filterMotion(mask, tr, condition)
}
}
}
hist(df$nacc_drugs_TR567mean)
df$Subject <- df$subjid
evalClassifier <- function(df, formula, type='glm', split.method='8020', sep.subjects=FALSE, print.model=FALSE){
# first get rid of any rows in which one of our variables is NA)
formula.vars <- unlist(strsplit(gsub("[^[:alnum:]|'_' ]", "", as.character(formula)), c(' ')))
for(v in formula.vars){
if(v %in% colnames(df)) {
df <- df[!is.na(df[v]), ]
}
}
# make our results data frame.
d.res <<- data.frame()
if(sep.subjects){
print("No separate subject implementation here.")
} else {
if(split.method=='loso'){
#eval_model on each subjects
if(type=='glm'){
print("Evaluating Entire Model")
# first evaluate the entire model so as to print model summary information
.evalClassifier(df, formula, type, split.method = 'none', print.model = print.model)
}
print("Beginning LOSO...")
for(subj in unique(df$Subject)){
print(nrow((filter(df, Subject==subj))))
accuracies <<- .evalClassifier(df, formula, type, split.method, test.sub=subj, print.model = print.model)
d.res<<- rbind(d.res, data.frame(Subject=subj, accuracies))
break
}
d.res <- d.res[order(-d.res$test.accuracy),] # order the subjects by their classifier accuracy
# add the average of all the subjects
d.res<- rbind(d.res, data.frame(Subject='Average', t(colMeans(d.res[,-1]))))
} else{
accuracies <- .evalClassifier(df, formula, type, split.method, print.model=TRUE)
d.res <- rbind(d.res, data.frame(data='All', accuracies))
}
}
d.res
}
.evalClassifier <- function(df, formula, type='glm', split.method='loso', test.sub = '',  print.model=FALSE){
y <- all.vars(formula)[1] # get the y variable name to do train test splits
if(split.method=='none' && type=='glm'){
m <- fitModel(df, df, formula, type, print.model=TRUE)
} else {
train.test <<- trainTestSplit(df, split.method, y=y,test.sub=test.sub)
m <- fitModel(df, train.test$train, formula, type, print.model)
train.accuracy <- modelAccuracy(m, y, train.test$train, type)
if(split.method=='loso'){
test.accuracy  <- modelAccuracy(m, y, train.test$test, type, one_prediction=T)
return( list('train.accuracy'=train.accuracy, 'test.accuracy'=test.accuracy[1], 'prediction'=test.accuracy[2], 'ground.truth' = test.accuracy[3]))
} else{
test.accuracy  <- modelAccuracy(m, y, train.test$test, type)
}
list('train.accuracy'=train.accuracy, 'test.accuracy'=test.accuracy[1])
}
}
trainTestSplit <- function(df, split.method='8020', y='result', test.sub="", downsample=TRUE){
set.seed(0)
# Assume that the two responses are levels 1, 2 of a factor
ind1 <- which(as.numeric(df[,y])==2)
ind0 <- which(as.numeric(df[,y])==1)
# downsample results. to upsample, use max and replace = TRUE
# uncomment section below for one_subj
if(downsample){
sampsize <- min(length(ind1), length(ind0))
sampind1 <- sample(ind1, sampsize, replace = FALSE)
sampind0 <- sample(ind0, sampsize, replace = FALSE)
sampind <- sample(c(sampind1,sampind0)) # the outside call to sample should randomize
} else{
sampind <- sample(1:nrow(df))
}
balanced.df <- df[sampind,]
#Change response levels to 0,1 from 1, 2
balanced.df[,y] <- factor(as.numeric(balanced.df[,y])-1, levels=c(0,1))
#return last day
if(split.method=='8020'){
nrows <- nrow(balanced.df)
train.ind <- sample(1:nrows, size=floor(.8 * nrows))
test.ind <- c(1:nrows)[!c(1:nrows) %in% train.ind]
d.train = balanced.df[train.ind,]
d.test  =balanced.df[test.ind,]
l <- list("train" = d.train, "test" = d.test)
} else if(split.method=='loso'){
train.ind <- balanced.df$Subject!= test.sub
test.ind <- balanced.df$Subject==test.sub
d.train <<- balanced.df[train.ind,]
d.test  <<- balanced.df[test.ind,]
l <- list("train" = d.train, "test" = d.test)
} else {
print('trainTestSplit called with split.method != 8020 or loso')
}
l
}
modelAccuracy <- function(m, y, d.test, type='glm', one_prediction=FALSE){
if(type=='glm'){
pred = predict(m, newdata = d.test, type = 'response', allow.new.levels = TRUE)
pred.bin = factor(ifelse(pred >= 0.5,1,0), levels = c(0,1))
}
if(type=='svm'){
pred = predict(m, d.test)
pred.bin <- factor(as.numeric(pred), levels=c(1,2), labels=c(0,1))
}
if(type=='naivebayes'){
pred = predict(m, d.test, type='raw')[,2]
pred.bin = factor(ifelse(pred >= 0.5,1,0), levels = c(0,1))
}
if(one_prediction){
prediction <- as.integer(pred.bin[1]) - 1
}
class.tab = table(real=d.test[,y], model=pred.bin)
#print(class.tab)
acc <- (class.tab[1,1])/sum(class.tab)
try(acc <- acc +  class.tab[2,2]/sum(class.tab))
if(one_prediction){
return(c(acc, prediction, as.integer(d.test[,y][1])-1))
}
acc
}
fitModel <- function(df, d.train, formula, type='glm', print.model=TRUE){
# glimpse(d.train)
needs.multilevel <- '|' %in% unlist(strsplit(gsub("[^[:alnum:]|'_' ]", "", as.character(formula)), c(' ')))
if(type=='glm'){
if(needs.multilevel){
null_formula <- as.formula(paste(as.character(formula)[2], '~', '(1 | Subject)'))
model <- glmer(formula, data = df, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
m2 <- glmer(null_formula, data = df, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
if(print.model){
print(summary(model), correlation=T)
if(needs.multilevel){
print(rsquared.glmm(model))
}
print(lrtest(m2, model))
print(anova(model))
#print(confint(model))
}
model <- glmer(formula, data = d.train, family = binomial(link = logit), control=glmerControl(optimizer="bobyqa"))
} else{
null_formula <- as.formula(paste(as.character(formula)[2], '~', '1'))
model <- glm(formula, data=df, family="binomial")
m2 <- glm(null_formula, data=df, family="binomial")
if(print.model){
print(summary(model))
print(PseudoR2(model))
print(lrtest(m2, model))
print(anova(model))
}
#print(summary(d.train))
model <- glm(formula, data=d.train, family="binomial")
}
}
if(type=='svm'){
model <- svm(formula, data=d.train)
}
if(type=='naivebayes'){
if(needs.multilevel){
print('naiveBayes cannot handle interaction terms')
} else{
model <-  naiveBayes(formula, data=d.train)
}
}
model
}
formula <- as.formula("relIn6Mos~ nacc_drugs_TR567mean + years_of_use + poly_drug_dep + craving + bdi + clinical_diag + age + smoke ")
res <- evalClassifier(df, formula, type='glm', split.method='loso')
kable(res)
class.tab = table(model=res$prediction[1:nrow(res)-1],ground.truth= res$ground.truth[1:nrow(res)-1])
print(class.tab)
formula <- as.formula("relIn6Mos~ nacc_drugs_beta + years_of_use + bam_upset ")
res <- evalClassifier(df, formula, type='glm', split.method='loso')
kable(res)
class.tab = table(model=res$prediction[1:nrow(res)-1],ground.truth= res$ground.truth[1:nrow(res)-1])
print(class.tab)
formula <- as.formula("relIn6Mos~ nacc_drugs_beta + age ")
res <- evalClassifier(df, formula, type='glm', split.method='loso')
kable(res)
class.tab = table(model=res$prediction[1:nrow(res)-1],ground.truth= res$ground.truth[1:nrow(res)-1])
print(class.tab)
